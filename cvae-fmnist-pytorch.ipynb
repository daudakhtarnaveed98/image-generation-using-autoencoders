{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd7474d-731a-4de0-96a5-bb7959045aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0963d77-de22-4c39-86b4-f3185d75a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Resize((32, 32))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "406d0eb1-01c1-44b3-b75a-b0f4257f5995",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNIST(root='dataset/', train=True, transform=transforms, target_transform=transforms, download=True)\n",
    "test_dataset = FashionMNIST(root='dataset/', train=False, transform=transforms, target_transform=transforms, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7110b078-cc28-4276-8822-89d048c95249",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Sampling, self).__init__()\n",
    "\n",
    "    def forward(self, z_mean, z_log_variance):\n",
    "        B, C = z_mean.shape\n",
    "        \n",
    "        mean = 0\n",
    "        std = 1\n",
    "        z_std = 0.5 * torch.exp(z_log_variance)\n",
    "\n",
    "        eps = torch.normal(mean, std, (B, C))\n",
    "        eps = eps.to(device)\n",
    "        z = z_mean + z_std * eps\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e231954-6436-49d5-8ed4-6f638bad99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.enc_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=11, out_channels=32, kernel_size=3, padding=1, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.enc_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.enc_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.enc_4 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=2048, out_features=2)\n",
    "        )\n",
    "        self.enc_5 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=2048, out_features=2)\n",
    "        )\n",
    "        self.sam_1 = Sampling()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.enc_1(x)\n",
    "        x = self.enc_2(x)\n",
    "        x = self.enc_3(x)\n",
    "        z_mean = self.enc_4(x)\n",
    "        z_log_variance = self.enc_5(x)\n",
    "        z = self.sam_1(z_mean, z_log_variance)\n",
    "        \n",
    "        return z_mean, z_log_variance, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a94077d2-97ca-46a4-a209-09824c9e1dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.dec_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=12, out_features=2048),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(128, 4, 4))\n",
    "        )\n",
    "        self.dec_2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=3, padding=1, output_padding=1, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.dec_3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, padding=1, output_padding=1, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.dec_4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=3, padding=1, output_padding=1, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.dec_5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=1, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dec_1(x)\n",
    "        x = self.dec_2(x)\n",
    "        x = self.dec_3(x)\n",
    "        x = self.dec_4(x)\n",
    "        x = self.dec_5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9075314-9c7b-426e-a0be-688de5d031b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "\n",
    "        self.ae_1 = encoder\n",
    "        self.ae_2 = decoder\n",
    "\n",
    "    def forward(self, x, l):\n",
    "        oh = F.one_hot(l, 10)\n",
    "        le = torch.unsqueeze(oh, -1)\n",
    "        le = torch.unsqueeze(le, -1)\n",
    "        le = le.repeat(1, 1, 32, 32)\n",
    "        x = torch.cat((x, le), dim=1)\n",
    "        z_mean, z_log_variance, z = self.ae_1(x)\n",
    "\n",
    "        z = torch.cat((z, oh), dim=1)\n",
    "        reconstruction = self.ae_2(z)\n",
    "        \n",
    "        return z_mean, z_log_variance, reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb5b985f-cc61-4d20-bab7-d780b532b109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c14f9d1-826a-47fd-a829-fea85dd4a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder().to(device)\n",
    "decoder = Decoder().to(device)\n",
    "\n",
    "model = VariationalAutoencoder(encoder, decoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb6a86e9-1b44-4c16-8278-82947585a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "batch_size = 512\n",
    "start_epoch = 0\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bc9e0fe-2c20-4c88-b27e-435d88a19406",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72fdf1e8-33f9-45ec-9334-1dd1455e21bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KLDivLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KLDivLoss, self).__init__()\n",
    "\n",
    "    def forward(self, z_log_variance, z_mean):\n",
    "        return torch.mean(-0.5 * torch.sum(1 + z_log_variance - torch.pow(z_mean, 2) - torch.exp(z_log_variance), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ba98644-57f8-447b-aed3-6918683e1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss = nn.BCELoss(reduction='none')\n",
    "kl_div_loss = KLDivLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4069f628-f5d9-4460-b80f-21821161a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint(model, filename):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "\n",
    "def resume(model, filename):\n",
    "    model.load_state_dict(torch.load(filename, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cba1fff7-ed39-4f49-a1d9-e5173d83ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "def train_loop(dataloader, model, bce_loss, kl_div_loss, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch, (image, label) in enumerate(dataloader):\n",
    "        i, l = image.to(device), label.to(device)\n",
    "        z_mean, z_log_variance, reconstruction = model(i, l)\n",
    "        \n",
    "        reconstruction_loss = torch.mean(500 * bce_loss(reconstruction, i))\n",
    "        kl_loss = kl_div_loss(z_log_variance, z_mean)\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += total_loss.item()\n",
    "        \n",
    "    train_loss /= num_batches    \n",
    "    print(f\"Avg. Train loss: {train_loss:>8f}\")\n",
    "\n",
    "\n",
    "# Copied from: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "def test_loop(dataloader, model, bce_loss, kl_div_loss):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (image, label) in enumerate(dataloader):\n",
    "            i, l = image.to(device), label.to(device)\n",
    "            z_mean, z_log_variance, reconstruction = model(i, l)\n",
    "\n",
    "            reconstruction_loss = torch.mean(500 * bce_loss(reconstruction, i))\n",
    "            kl_loss = kl_div_loss(z_log_variance, z_mean)\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "            test_loss += total_loss.item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg. Test loss: {test_loss:>8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507874d-6533-4559-a9aa-d21845fa1838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Avg. Train loss: 192.464712\n",
      "Avg. Test loss: 171.534460\n",
      "Epoch time: 12.887245416641235\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Avg. Train loss: 167.826374\n",
      "Avg. Test loss: 169.261424\n",
      "Epoch time: 12.721989154815674\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Avg. Train loss: 166.011442\n",
      "Avg. Test loss: 166.328666\n",
      "Epoch time: 12.874197483062744\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Avg. Train loss: 165.244310\n",
      "Avg. Test loss: 166.114014\n",
      "Epoch time: 12.858962297439575\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Avg. Train loss: 164.665600\n",
      "Avg. Test loss: 165.730865\n",
      "Epoch time: 13.096653461456299\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Avg. Train loss: 164.410780\n",
      "Avg. Test loss: 165.780692\n",
      "Epoch time: 12.775063753128052\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Avg. Train loss: 164.229046\n",
      "Avg. Test loss: 165.256458\n",
      "Epoch time: 12.746533632278442\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Avg. Train loss: 164.114797\n",
      "Avg. Test loss: 165.280851\n",
      "Epoch time: 12.585347414016724\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Avg. Train loss: 164.040059\n",
      "Avg. Test loss: 165.812152\n",
      "Epoch time: 12.781795978546143\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Avg. Train loss: 163.919298\n",
      "Avg. Test loss: 164.989168\n",
      "Epoch time: 12.610260248184204\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Avg. Train loss: 164.088760\n",
      "Avg. Test loss: 165.349428\n",
      "Epoch time: 12.73937463760376\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Avg. Train loss: 163.793321\n",
      "Avg. Test loss: 165.230016\n",
      "Epoch time: 12.678963422775269\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Avg. Train loss: 163.593130\n",
      "Avg. Test loss: 164.794989\n",
      "Epoch time: 12.62999939918518\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Avg. Train loss: 163.580337\n",
      "Avg. Test loss: 164.999284\n",
      "Epoch time: 12.752179384231567\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Avg. Train loss: 163.460697\n",
      "Avg. Test loss: 164.995868\n",
      "Epoch time: 12.611938714981079\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Avg. Train loss: 163.422476\n",
      "Avg. Test loss: 165.011074\n",
      "Epoch time: 12.669204950332642\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Avg. Train loss: 163.362153\n",
      "Avg. Test loss: 164.827673\n",
      "Epoch time: 12.977701425552368\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Avg. Train loss: 163.527289\n",
      "Avg. Test loss: 165.269823\n",
      "Epoch time: 12.756752252578735\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Avg. Train loss: 163.594386\n",
      "Avg. Test loss: 165.521175\n",
      "Epoch time: 12.562492609024048\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Avg. Train loss: 163.485488\n",
      "Avg. Test loss: 164.514956\n",
      "Epoch time: 12.710442066192627\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Avg. Train loss: 163.225752\n",
      "Avg. Test loss: 164.783475\n",
      "Epoch time: 12.730452060699463\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Avg. Train loss: 163.281104\n",
      "Avg. Test loss: 165.376498\n",
      "Epoch time: 12.609896421432495\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Avg. Train loss: 163.318868\n",
      "Avg. Test loss: 164.884751\n",
      "Epoch time: 12.689197778701782\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Avg. Train loss: 163.397791\n",
      "Avg. Test loss: 164.693915\n",
      "Epoch time: 12.5225989818573\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Copied from: https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "if start_epoch > 0:\n",
    "    resume_epoch = start_epoch - 1\n",
    "    resume(model, f\"checkpoints/epoch-{resume_epoch}.pth\")\n",
    "\n",
    "for t in range(start_epoch, epochs):\n",
    "    t0 = time.time()\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, bce_loss, kl_div_loss, optimizer)\n",
    "    test_loop(test_dataloader, model, bce_loss, kl_div_loss)\n",
    "    print(f\"Epoch time: {time.time() - t0}\\n\")\n",
    "    checkpoint(model, f\"checkpoints/epoch-{t}.pth\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24213440-a72c-4593-a2ce-7877a9acd896",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_indices = [random.randint(0, test_dataset.__len__() - 1) for i in range(10)]\n",
    "data_subset = Subset(test_dataset, subset_indices)\n",
    "data_subset_loader = DataLoader(data_subset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa75b04-cf58-4a9f-8286-f48a3dc8a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_and_plot_results(dataloader, model):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (image, label) in enumerate(dataloader):\n",
    "            i, l = image.to(device), label.to(device)\n",
    "            z_mean, z_log_variance, reconstruction = model(i, l)\n",
    "\n",
    "            fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\n",
    "            fig.supylabel(f'Test Output')\n",
    "            fig.tight_layout()\n",
    "            \n",
    "            ax1.imshow(torch.permute(reconstruction[0], (1, 2, 0)).cpu().data.numpy(), cmap='gray')\n",
    "            ax1.set_title('Prediction')\n",
    "            ax2.imshow(torch.permute(i[0], (1, 2, 0)).cpu().data.numpy(), cmap='gray')\n",
    "            ax2.set_title('Reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0fadf-a54f-447d-815e-727e09b20b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_and_plot_results(data_subset_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52db3db-bf66-4e79-a161-1ec9abd5186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent_space(encoder):\n",
    "    embeddings = []\n",
    "    \n",
    "    for _, (i, l) in enumerate(test_dataloader):\n",
    "        i = i.to(device)\n",
    "        l = l.to(device)\n",
    "        oh = F.one_hot(l, 10)\n",
    "        le = torch.unsqueeze(oh, -1)\n",
    "        le = torch.unsqueeze(le, -1)\n",
    "        le = le.repeat(1, 1, 32, 32)\n",
    "        x = torch.cat((i, le), dim=1)\n",
    "        \n",
    "        z_mean, z_log_variance, z = encoder(x)\n",
    "        z = z.cpu().data.numpy()\n",
    "        embeddings.append(z)\n",
    "\n",
    "    embeddings = np.concatenate(embeddings)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(x=embeddings[:, 0], y=embeddings[:, 1], s=1, alpha=0.5, c='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957eb866-4d07-43fb-99c3-6e3a1f0c7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_latent_space(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87178d0-435c-4b56-b76e-9928d9fa6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_random_sample(decoder):\n",
    "    embedding = torch.abs(torch.randn((1, 2)) * 1).to(device)\n",
    "    l = torch.tensor([0]).to(device)\n",
    "    oh = F.one_hot(l, 10)\n",
    "    x = torch.cat((embedding, oh), dim=1)\n",
    "   \n",
    "    p = decoder(x)\n",
    "    p = p[0].permute((1, 2, 0)).cpu().data.numpy()\n",
    "    \n",
    "    plt.figure(figsize=(1, 1))\n",
    "    plt.imshow(p, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba9cf2-4426-4562-8d38-8c69880b6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_random_sample(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32daf99a-af8f-4468-84bd-55029ff2fa20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
